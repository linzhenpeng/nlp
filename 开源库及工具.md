### **Anaconda**

Anaconda指的是一个开源的[Python](https://baike.baidu.com/item/Python)发行版本，其包含了conda、Python等180多个科学包及其依赖项。 [1]  因为包含了大量的科学包，Anaconda 的下载文件比较大（约 531 MB），如果只需要某些包，或者需要节省带宽或存储空间，也可以使用**Miniconda**这个较小的发行版（仅包含conda和 Python）。

### **tensorflow**

TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。

### **nltk**

NLTK是一个高效的Python构建的平台，用来处理人类自然语言数据。它提供了易于使用的接口，通过这些接口可以访问[超过50个语料库和词汇资源](http://nltk.org/nltk_data/)（如WordNet），还有一套用于分类、标记化、词干标记、解析和语义推理的文本处理库，以及工业级NLP库的封装器和一个活跃的[讨论论坛](http://groups.google.com/group/nltk-users)。

### **gensim**

Gensim是一款开源的第三方Python工具包，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。 
它支持包括TF-IDF，LSA，LDA，和word2vec在内的多种主题模型算法， 
支持流式训练，并提供了诸如相似度计算，信息检索等一些常用任务的API接口

### **jieba中文分词**  

 Python 中文分词组件，它主要有以下 3 种特性：

- 支持 3 种分词模式：精确模式、全模式、搜索引擎模式
- 支持繁体分词
- 支持自定义词典

### stanford nlp

[CoreNLP](https://github.com/stanfordnlp/CoreNLP)是由斯坦福大学开源的一套Java NLP工具，提供诸如：词性标注（part-of-speech (POS) tagger）、命名实体识别（named entity recognizer (NER)）、情感分析（sentiment analysis）等功能。

### sklearn

Scikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法







