{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n",
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "['eps', 'user', 'interface', 'system'],\n",
    "['system', 'human', 'system', 'eps'],\n",
    "['user', 'response', 'time'],\n",
    "['trees'],\n",
    "['graph', 'trees'],\n",
    "['graph', 'minors', 'trees'],\n",
    "['graph', 'minors', 'survey']]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ItemsView(<gensim.corpora.dictionary.Dictionary object at 0x000001D45A10EB70>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=9, num_nnz=28)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.70710678118654757), (3, 0.70710678118654757)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dow=[(0,1),(3,1)]\n",
    "tfidf[doc_dow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim实际上手使用该目录下data文件夹做为我们的预料进行测试,注:该预料来着人民日报2014年的一部分\n",
    "其每个文件就是一篇新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import jieba,re,os\n",
    "from gensim.models import word2vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对文件进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建停用词列表\n",
    "def stopwordslist():\n",
    "    stopwords = [line.strip() for line in open('stopwords.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwords\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitSentence(inputfile,fout,stopwords):      #语料处理：去符号，数字字母 分词 (删除非中文字符)\n",
    "    fin = open(inputfile,'r',encoding=\"utf-8\")\n",
    "    for line in fin:\n",
    "#         line1 = line.strip().decode('utf-8','ignore')\n",
    "#         line2 = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、★~@#￥%……&*“”➕「」《》（）]+|[０-９0-9a-zA-Z]+\", \"\", line)\n",
    "        line2 = re.sub(\"[^\\u4e00-\\u9fff]+\", \"\", line)\n",
    "        wordlist = list(jieba.cut(line2))\n",
    "        outstr = ''\n",
    "        for word in wordlist:\n",
    "            if word not in stopwords:\n",
    "                outstr += word\n",
    "                outstr += ' '\n",
    "        fout.write(outstr.strip())\n",
    "    fout.write('\\n')\n",
    "    fin.close()\n",
    "def TextLoader(dir):\n",
    "    fout = open('SplitSentence.txt', 'w',encoding=\"utf-8\")\n",
    "    stopwords=stopwordslist()\n",
    "    for root, dirs, files in os.walk(dir):      # 遍历所有文件夹\n",
    "        for file in files:\n",
    "            inputfile = os.path.join(root, file)\n",
    "#             print(inputfile)     #打印文件记录\n",
    "            SplitSentence(inputfile,fout,stopwords)   #处理该文件\n",
    "    fout.close()\n",
    "TextLoader(\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "2019-06-15 16:53:50,959 : INFO : collecting all words and their counts\n",
      "2019-06-15 16:53:50,961 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 16:53:50,967 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-06-15 16:53:51,113 : INFO : collected 32002 word types from a corpus of 177407 raw words and 18 sentences\n",
      "2019-06-15 16:53:51,116 : INFO : Loading a fresh vocabulary\n",
      "2019-06-15 16:53:51,300 : INFO : effective_min_count=5 retains 6633 unique words (20% of original 32002, drops 25369)\n",
      "2019-06-15 16:53:51,302 : INFO : effective_min_count=5 leaves 136915 word corpus (77% of original 177407, drops 40492)\n",
      "2019-06-15 16:53:51,358 : INFO : deleting the raw counts dictionary of 32002 items\n",
      "2019-06-15 16:53:51,364 : INFO : sample=0.001 downsamples 17 most-common words\n",
      "2019-06-15 16:53:51,367 : INFO : downsampling leaves estimated 134406 word corpus (98.2% of prior 136915)\n",
      "2019-06-15 16:53:51,425 : INFO : estimated required memory for 6633 words and 100 dimensions: 8622900 bytes\n",
      "2019-06-15 16:53:51,427 : INFO : resetting layer weights\n",
      "2019-06-15 16:53:51,629 : INFO : training model with 3 workers on 6633 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-06-15 16:53:51,639 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 16:54:08,572 : INFO : EPOCH 1 - PROGRESS: at 5.56% examples, 474 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:54:09,833 : INFO : EPOCH 1 - PROGRESS: at 11.11% examples, 855 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:54:24,616 : INFO : EPOCH 1 - PROGRESS: at 22.22% examples, 937 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:54:26,619 : INFO : EPOCH 1 - PROGRESS: at 27.78% examples, 1094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:54:40,317 : INFO : EPOCH 1 - PROGRESS: at 38.89% examples, 1089 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:54:43,773 : INFO : EPOCH 1 - PROGRESS: at 44.44% examples, 1159 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:54:56,239 : INFO : EPOCH 1 - PROGRESS: at 55.56% examples, 1174 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:55:01,432 : INFO : EPOCH 1 - PROGRESS: at 61.11% examples, 1194 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:55:02,581 : INFO : EPOCH 1 - PROGRESS: at 66.67% examples, 1287 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:55:12,631 : INFO : EPOCH 1 - PROGRESS: at 72.22% examples, 1220 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:55:19,225 : INFO : EPOCH 1 - PROGRESS: at 77.78% examples, 1211 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-15 16:55:29,336 : INFO : EPOCH 1 - PROGRESS: at 88.89% examples, 1243 words/s, in_qsize 2, out_qsize 1\n",
      "2019-06-15 16:55:29,340 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-15 16:55:31,761 : INFO : EPOCH 1 - PROGRESS: at 94.44% examples, 1272 words/s, in_qsize 1, out_qsize 1\n",
      "2019-06-15 16:55:31,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-15 16:55:32,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-15 16:55:32,268 : INFO : EPOCH - 1 : training on 177407 raw words (134418 effective words) took 100.6s, 1336 effective words/s\n",
      "2019-06-15 16:55:32,274 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 16:55:47,499 : INFO : EPOCH 2 - PROGRESS: at 5.56% examples, 496 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:55:49,108 : INFO : EPOCH 2 - PROGRESS: at 11.11% examples, 908 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:55:51,885 : INFO : EPOCH 2 - PROGRESS: at 16.67% examples, 1188 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:03,115 : INFO : EPOCH 2 - PROGRESS: at 22.22% examples, 1001 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:04,568 : INFO : EPOCH 2 - PROGRESS: at 27.78% examples, 1185 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:11,738 : INFO : EPOCH 2 - PROGRESS: at 33.33% examples, 1160 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:56:19,260 : INFO : EPOCH 2 - PROGRESS: at 38.89% examples, 1128 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:22,387 : INFO : EPOCH 2 - PROGRESS: at 44.44% examples, 1205 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:28,817 : INFO : EPOCH 2 - PROGRESS: at 50.00% examples, 1200 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:36,322 : INFO : EPOCH 2 - PROGRESS: at 55.56% examples, 1184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:39,570 : INFO : EPOCH 2 - PROGRESS: at 61.11% examples, 1238 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:56:48,662 : INFO : EPOCH 2 - PROGRESS: at 66.67% examples, 1195 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:56:52,829 : INFO : EPOCH 2 - PROGRESS: at 72.22% examples, 1227 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:56:58,051 : INFO : EPOCH 2 - PROGRESS: at 77.78% examples, 1240 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-15 16:57:06,397 : INFO : EPOCH 2 - PROGRESS: at 83.33% examples, 1207 words/s, in_qsize 3, out_qsize 0\n",
      "2019-06-15 16:57:09,472 : INFO : EPOCH 2 - PROGRESS: at 88.89% examples, 1249 words/s, in_qsize 2, out_qsize 1\n",
      "2019-06-15 16:57:09,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-15 16:57:12,126 : INFO : EPOCH 2 - PROGRESS: at 94.44% examples, 1287 words/s, in_qsize 1, out_qsize 1\n",
      "2019-06-15 16:57:12,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-15 16:57:13,330 : INFO : EPOCH 2 - PROGRESS: at 100.00% examples, 1330 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-15 16:57:13,332 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-15 16:57:13,333 : INFO : EPOCH - 2 : training on 177407 raw words (134358 effective words) took 101.0s, 1330 effective words/s\n",
      "2019-06-15 16:57:13,338 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 16:57:31,382 : INFO : EPOCH 3 - PROGRESS: at 5.56% examples, 430 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:57:32,392 : INFO : EPOCH 3 - PROGRESS: at 16.67% examples, 1225 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:57:48,106 : INFO : EPOCH 3 - PROGRESS: at 22.22% examples, 889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:57:50,463 : INFO : EPOCH 3 - PROGRESS: at 33.33% examples, 1234 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:58:03,877 : INFO : EPOCH 3 - PROGRESS: at 38.89% examples, 1049 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:58:05,224 : INFO : EPOCH 3 - PROGRESS: at 44.44% examples, 1165 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:58:08,328 : INFO : EPOCH 3 - PROGRESS: at 50.00% examples, 1234 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:58:22,774 : INFO : EPOCH 3 - PROGRESS: at 55.56% examples, 1085 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:58:24,777 : INFO : EPOCH 3 - PROGRESS: at 66.67% examples, 1278 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:58:39,824 : INFO : EPOCH 3 - PROGRESS: at 72.22% examples, 1140 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:58:40,910 : INFO : EPOCH 3 - PROGRESS: at 77.78% examples, 1211 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-15 16:58:52,856 : INFO : EPOCH 3 - PROGRESS: at 88.89% examples, 1201 words/s, in_qsize 2, out_qsize 1\n",
      "2019-06-15 16:58:52,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-15 16:58:55,656 : INFO : EPOCH 3 - PROGRESS: at 94.44% examples, 1238 words/s, in_qsize 1, out_qsize 1\n",
      "2019-06-15 16:58:55,660 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-15 16:58:55,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-15 16:58:55,764 : INFO : EPOCH - 3 : training on 177407 raw words (134407 effective words) took 102.4s, 1312 effective words/s\n",
      "2019-06-15 16:58:55,768 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 16:59:12,328 : INFO : EPOCH 4 - PROGRESS: at 5.56% examples, 455 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:59:13,425 : INFO : EPOCH 4 - PROGRESS: at 11.11% examples, 866 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-15 16:59:14,602 : INFO : EPOCH 4 - PROGRESS: at 16.67% examples, 1238 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:59:28,975 : INFO : EPOCH 4 - PROGRESS: at 22.22% examples, 930 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:59:30,261 : INFO : EPOCH 4 - PROGRESS: at 27.78% examples, 1109 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:59:33,328 : INFO : EPOCH 4 - PROGRESS: at 33.33% examples, 1219 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:59:45,549 : INFO : EPOCH 4 - PROGRESS: at 38.89% examples, 1064 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 16:59:47,923 : INFO : EPOCH 4 - PROGRESS: at 44.44% examples, 1158 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 16:59:50,699 : INFO : EPOCH 4 - PROGRESS: at 50.00% examples, 1234 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:00:01,596 : INFO : EPOCH 4 - PROGRESS: at 55.56% examples, 1151 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:00:03,865 : INFO : EPOCH 4 - PROGRESS: at 61.11% examples, 1223 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:00:11,192 : INFO : EPOCH 4 - PROGRESS: at 66.67% examples, 1210 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 17:00:19,601 : INFO : EPOCH 4 - PROGRESS: at 72.22% examples, 1178 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:00:21,059 : INFO : EPOCH 4 - PROGRESS: at 77.78% examples, 1247 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-15 17:00:27,627 : INFO : EPOCH 4 - PROGRESS: at 83.33% examples, 1237 words/s, in_qsize 3, out_qsize 0\n",
      "2019-06-15 17:00:36,297 : INFO : EPOCH 4 - PROGRESS: at 88.89% examples, 1207 words/s, in_qsize 2, out_qsize 1\n",
      "2019-06-15 17:00:36,302 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-15 17:00:37,992 : INFO : EPOCH 4 - PROGRESS: at 94.44% examples, 1257 words/s, in_qsize 1, out_qsize 1\n",
      "2019-06-15 17:00:37,996 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-15 17:00:38,447 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-15 17:00:38,449 : INFO : EPOCH - 4 : training on 177407 raw words (134356 effective words) took 102.7s, 1309 effective words/s\n",
      "2019-06-15 17:00:38,454 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 17:00:54,136 : INFO : EPOCH 5 - PROGRESS: at 5.56% examples, 481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:00:55,854 : INFO : EPOCH 5 - PROGRESS: at 11.11% examples, 880 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 17:00:57,126 : INFO : EPOCH 5 - PROGRESS: at 16.67% examples, 1250 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:09,630 : INFO : EPOCH 5 - PROGRESS: at 22.22% examples, 991 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:13,397 : INFO : EPOCH 5 - PROGRESS: at 27.78% examples, 1096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:14,801 : INFO : EPOCH 5 - PROGRESS: at 33.33% examples, 1260 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:23,307 : INFO : EPOCH 5 - PROGRESS: at 38.89% examples, 1182 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:32,128 : INFO : EPOCH 5 - PROGRESS: at 44.44% examples, 1126 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:40,036 : INFO : EPOCH 5 - PROGRESS: at 55.56% examples, 1232 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 17:01:50,659 : INFO : EPOCH 5 - PROGRESS: at 61.11% examples, 1154 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-15 17:01:53,623 : INFO : EPOCH 5 - PROGRESS: at 66.67% examples, 1215 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:01:57,901 : INFO : EPOCH 5 - PROGRESS: at 72.22% examples, 1244 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-15 17:02:10,221 : INFO : EPOCH 5 - PROGRESS: at 77.78% examples, 1156 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-15 17:02:14,459 : INFO : EPOCH 5 - PROGRESS: at 88.89% examples, 1265 words/s, in_qsize 2, out_qsize 1\n",
      "2019-06-15 17:02:14,463 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-15 17:02:20,570 : INFO : EPOCH 5 - PROGRESS: at 94.44% examples, 1247 words/s, in_qsize 1, out_qsize 1\n",
      "2019-06-15 17:02:20,573 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-15 17:02:21,057 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-15 17:02:21,059 : INFO : EPOCH - 5 : training on 177407 raw words (134351 effective words) took 102.6s, 1310 effective words/s\n",
      "2019-06-15 17:02:21,061 : INFO : training on a 887035 raw words (671890 effective words) took 509.4s, 1319 effective words/s\n",
      "2019-06-15 17:02:21,063 : INFO : saving Word2Vec object under vector.bin, separately None\n",
      "2019-06-15 17:02:21,065 : INFO : not storing attribute vectors_norm\n",
      "2019-06-15 17:02:21,068 : INFO : not storing attribute cum_table\n",
      "2019-06-15 17:02:21,070 : WARNING : this function is deprecated, use smart_open.open instead\n",
      "2019-06-15 17:02:21,516 : INFO : saved vector.bin\n"
     ]
    }
   ],
   "source": [
    "def Training():\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)   #打印日志\n",
    "    sentences = word2vec.Text8Corpus('SplitSentence.txt')  # 加载语料\n",
    "    model = word2vec.Word2Vec(sentences)  # 训练skip-gram模型; 默认参数\n",
    "    model.save('vector.bin')\n",
    "Training()\n",
    "#model = word2vec.Word2Vec(sentences, sg=1, size=100, window=5, min_count=5, negative=3, sample=0.001, hs=1, workers=4)\n",
    "#\n",
    "# sentences：可以是一个list，对于大语料集，建议使用BrownCorpus,Text8Corpus或·ineSentence构建。\n",
    "#\n",
    "# sg：用于设置训练算法，默认为0，对应CBOW算法；sg=1则采用skip-gram算法,对低频词敏感；默认sg=0为CBOW算法。\n",
    "#\n",
    "# size是输出词向量的维数，值太小会导致词映射因为冲突而影响结果，值太大则会耗内存并使算法计算变慢，一般值取为几十到几百之间。默认为100\n",
    "#\n",
    "# window是句子中当前词与目标词之间的最大距离，3表示在目标词前看3-b个词，后面看b个词（b在0-3之间随机）。\n",
    "#\n",
    "# min_count是对词进行过滤，频率小于min-count的单词则会被忽视，默认值为5。\n",
    "#\n",
    "# negative和sample可根据训练结果进行微调，sample表示更高频率的词被随机下采样到所设置的阈值，默认值为1e-3。\n",
    "#\n",
    "# hs=1表示层级softmax将会被使用，默认hs=0且negative不为0，则负采样将会被选择使用。\n",
    "#\n",
    "# workers控制训练的并行，此参数只有在安装了Cpython后才有效，否则只能使用单核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus('SplitSentence.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
