作者博客:http://www.hankcs.com/nlp/hanlp.html

github:  https://github.com/hankcs/HanLP

**HanLP**是由一系列模型与算法组成的Java工具包，目标是促进自然语言处理在生产环境中的应用。**HanLP**具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。

支持中文分词（N-最短路分词、CRF分词、索引分词、用户自定义词典、词性标注），命名实体识别（中国人名、音译人名、日本人名、地名、实体机构名识别），关键词提取，自动摘要，短语提取，拼音转换，简繁转换，文本推荐，依存句法分析（MaxEnt依存句法分析、神经网络依存句法分析）。提供Lucene插件，兼容Solr和ElasticSearch。

**HanLP**提供下列功能：

- 中文分词

- - 最短路分词
  - N-最短路分词
  - CRF分词
  - 索引分词
  - 极速词典分词
  - 用户自定义词典

- 词性标注

- 命名实体识别

- - 中国人名识别
  - 音译人名识别
  - 日本人名识别
  - 地名识别
  - 实体机构名识别

- 关键词提取

- - TextRank关键词提取

- 自动摘要

- - TextRank自动摘要

- 短语提取

- - 基于互信息和左右信息熵的短语提取

- 拼音转换

- - 多音字
  - 声母
  - 韵母
  - 声调

- 简繁转换

- - 繁体中文分词
  - 简繁分歧词

- 文本推荐

- - 语义推荐
  - 拼音推荐
  - 字词推荐

- 依存句法分析

- - 基于神经网络的高性能依存句法分析器
  - MaxEnt依存句法分析
  - CRF依存句法分析

- 语料库工具

- - 分词语料预处理
  - 词频词性词典制作
  - BiGram统计
  - 词共现统计
  - CoNLL语料预处理
  - CoNLL UA/LA/DA评测工具

在提供丰富功能的同时，**HanLP**内部模块坚持低耦合、模型坚持惰性加载、服务坚持静态提供、词典坚持明文发布，使用非常方便，同时自带一些语料处理工具，帮助用户训练自己的语料。

