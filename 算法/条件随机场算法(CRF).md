

https://www.cnblogs.com/pinard/p/7048333.html

https://www.cnblogs.com/pinard/p/7055072.html

https://www.cnblogs.com/pinard/p/7068574.html

https://www.jianshu.com/p/5d6a03c1f83f

http://www.52nlp.cn/tag/crf

[LSTM+CRF介绍](https://x-algo.cn/index.php/2017/01/16/1639/)

[NLP --- 条件随机场CRF背景](https://blog.csdn.net/weixin_42398658/article/details/84958993)

[NLP --- 条件随机场CRF详解](https://blog.csdn.net/weixin_42398658/article/details/85156721)

[NLP --- 条件随机场CRF（概率计算问题）](https://blog.csdn.net/weixin_42398658/article/details/85207991)

#### 背景

隐马尔可夫可以通过可观察符号计算转态转移概率，如下图所示：

![img](F:\git\nlp\算法\images\CRF\20181211190949422.png)

在HMM中我们假设发射符号是条件独立的，上图的发射符号是x，转态转移是Y，其实呢x假设独立很牵强，而在CRF中的定义下面的样子：

![img](F:\git\nlp\算法\images\CRF\20181211191203147.png)



即**每个发射符号都不是独立的，每个x都会影响Y**，这是比较符合语言模型的，因为我们人类在说话时已经将一句话的意群都想到了，而不是一个字一个字的去想，上图就比较符合我们的语言思维，好，现在我们有了模型，关键是如何建立他们的联系呢？或者说是如何使用数学来表示他们呢？首先呢我们可以确定的是他应该是这个形式：,即在输入语音的条件下，对应的汉字句子大概率是多大，这是我们语言模型最基本需要解决的问题，下面我们就详细的讲解如何一步步建立数学模型的过程。这里我们就需要引入我们以前讲的概率图模型了，不懂的请参考我的这篇文章，还需要知道无向图的团，下面分别简单的讲解一下：

![img](F:\git\nlp\算法\images\CRF\20181211192945685.png)

如上图的无向图，那么这里的概率图模型是什么意思呢？其实很简单，例如A的条件概率只和C和B有关，而和D无关，也就是说，某个点的条件概率只和他相邻的点有关和其他点无关，例如下式：

![](F:\git\nlp\算法\images\CRF\2018122013024095.png)

![](F:\git\nlp\算法\images\CRF\20181220130240115.png)

下面在简单的讲解一下什么是最大团：

![img](F:\git\nlp\算法\images\CRF\20181211193341992.png)

其实很简单，我们先看定义如下：

定义：（团与最大团）无向图G中任何两个结点均有边连接的结点子集称为团(clique).若c是无向图G的一个团，并且不能再加进任何一个G的结点使其成为一个更大的团，则称此c为最大团(maximalclique). 

上图有两个节点的团有5个基![](F:\git\nlp\算法\images\CRF\20181220130240132.png)

,其中有三个节点的团有两个即![](F:\git\nlp\算法\images\CRF\20181220130240153.png)

两个，而ABD就不是一个团，因为AD没相连。

将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解(factorization).给定概率无向图模型，设其无向图为G，C为G上的最大团，表示C对应的随机变量，那么概率无向图模型的联合概率分布可写作图中所有最大团C上的函数的乘积形式，即

![1564025473321](F:\git\nlp\算法\images\CRF\1564025473321.png)

我现在再来看看能看出什么门道呢？其实这就是我们上面说的概率和团嘛，其实就是他，那么我们就按照上面的进行构造模型即可，这里我直接构造好的模型拿过来讲解好了，如下：

![img](F:\git\nlp\算法\images\CRF\20181211195837130.png)

这里的定义大家不要想的太麻烦，其实很简单的，他就是一个势函数，只是上面的势函数E使用具体的形式来代替罢了，这里我们需要详细解释的是![\lambda _k](https://img-blog.csdnimg.cn/20181220130240410)、![t_k(\bullet )](https://img-blog.csdnimg.cn/20181220130240426),![\mu _l](https://img-blog.csdnimg.cn/20181220130240437),![s_l(\bullet )](https://img-blog.csdnimg.cn/20181220130240454)分别代表什么，在讲解之前我们先来看看上式的为什么是求和呢，其实是根据上面的概率定义，如下所来：

![](F:\git\nlp\算法\images\CRF\varphi.png)

本来是连乘的，但是因为是指数连乘，所以指数就是相加了，下面我们解释一下上面的符号的意义，大家这里可以把、看做权值，、看做特征函数，和我们最大熵模型里将的特征函数很类似可以说是一样了，即满足为1，反之为0。

#### CRF定义

这里定义只讲线性链随机场，针对自然语言处理领域的处理进行设计，因此这里只提线性链随机场定义：

线性链条件随机场）设![](F:\git\nlp\算法\images\CRF\x向量.png),![](F:\git\nlp\算法\images\CRF\20181221092031623.png)均为线性链表示的随机变量序列，若在给定随机变量序列的条件下，随机变量序列Y的条件概率分布就构成条件随机场，即满足马尔可夫性
                                               ![](F:\git\nlp\算法\images\CRF\马尔科夫性.png)
则称为线性链条件随机场，在标注问题中，表示输入观测序列，表示对应的输出标记序列或状态序列，这里大家一定要切记什么是概率图模型，什么是无向图和团，上面的定义就是针对二元组，如下图：

![](F:\git\nlp\算法\images\CRF\20181212093001756.png)



上面团就是![\mathbf{X},Y_1,Y_2](https://private.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Cmathbf%7BX%7D%2CY_1%2CY_2),其他的Y不是这个团里的，那么对应的条件概率（这里以为例求解） 那么应该写成如下：

​                                               ![P(Y_2|X,Y_1,Y_2,Y_3,..,Y_n) = P(Y_2|X,Y_{1},Y_{3})](https://private.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20P%28Y_2%7CX%2CY_1%2CY_2%2CY_3%2C..%2CY_n%29%20%3D%20P%28Y_2%7CX%2CY_%7B1%7D%2CY_%7B3%7D%29)

也就是说决定Y2的概率取决于输入X的序列以及和他相连的两个输出,，这正是体现了概率图模型里面的思想(符合语言的规律即联系上下文语意)，不和其直接相连的可以看做条件独立，这就解释了下面为什么可以直接相乘，指数相加了，所以这里大家需要好好理解这里的深层含义，不要放过任何细节问题。下面我们给出参数化定义，上面的定义是我们语言模型最原始的出发点即知道输入的语音我如何求出对应的概率，这里需要数学模型来建立他们的关系，如下（这里大家看看上一节的什么是势函数，或者看李航的书）：












