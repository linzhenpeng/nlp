https://www.jianshu.com/p/53e379483f3e

https://blog.csdn.net/weixin_41090915/article/details/79053584

bm25 是一种用来评价搜索词和文档之间相关性的算法，它是一种基于**概率检索模型**提出的算法，再用简单的话来描述下bm25算法：我们有一个query和一批文档Ds，现在要计算query和每篇文档D之间的相关性分数，我们的做法是，先对query进行切分，得到单词$q_i$，然后单词的分数由3部分组成：

- 单词$q_i$和D之间的相关性
- 单词$q_i$和D之间的相关性
- 每个单词的权重

最后对于每个单词的分数我们做一个求和，就得到了query和文档之间的分数。

二、算法核心
BM25算法是一种常见用来做相关度打分的公式，思路比较简单，主要就是计算一个query里面所有词$q_1,q_2...q_n$和文档的相关度，然后再把分数做累加操作。公式如下： 
$Score(Q,d)=\sum_i^nW_i⋅R(q_i,d)​$

其中$R(q_i,d)$是查询语句query中每个词$q_i$和文档$d$的相关度值，$W_i$是该词的权重，最后将所有词的$W_i∗R(q_i,d)$相加。
$W_i$一般情况下为IDF(InverseDocumentFrequency)值，即逆向文档频率，公式如下： 
$IDF(q_i)=log\frac{N+0.5}{n(q_i)+0.5}​$

其中N是文档总数，$n(q_i)$是包含该词的文档数，0.5是调教系数，避免$n(q_i)=0$的情况。log函数是为了让IDF的值受N和$n(q_i)$的影响更加平滑。 
从公式中显然能看出IDF值的含义：即总文档数越大，包含词$q_i$的文档数越小，则$q_i​$的IDF值越大。 
白话举例就是：比如我们有1万篇文档，而单词basketball,Kobe Bryant几乎只在和体育运动有关的文档中出现，说明这两个词的IDF值比较大，而单词is, are, what几乎在所有文档中都有出现，那么这几个单词的IDF值就非常小。